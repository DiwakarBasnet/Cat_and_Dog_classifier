{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo05diRAE+LwxP2t432LWg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiwakarBasnet/Cat_and_Dog_classifier/blob/main/training1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a1_kB9vDQ5Pi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "w_JbN-OZEjQx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from kaggle into tf.dataset"
      ],
      "metadata": {
        "id": "YQtLMobUmph0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWvc3NGgSGkg",
        "outputId": "3401a162-089c-4978-fb3b-eb7f2c7e926a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "h1kNqGtGSaHY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "6XZRMIXiSf27"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "w_V1rRxkSnsa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d shaunthesheep/microsoft-catsvsdogs-dataset --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM08qYXgSyJh",
        "outputId": "f6ee4aaa-540f-4b95-f703-10b67861544f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading microsoft-catsvsdogs-dataset.zip to /content\n",
            " 99% 782M/788M [00:03<00:00, 282MB/s]\n",
            "100% 788M/788M [00:03<00:00, 242MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove any files from dataset that is not jpg format\n",
        "import os\n",
        "import imghdr\n",
        "\n",
        "path1 = 'PetImages/Cat/' \n",
        "path2 = 'PetImages/Dog/'\n",
        "\n",
        "files1 = os.listdir(path1)\n",
        "files2 = os.listdir(path2)\n",
        "\n",
        "for file in files1:\n",
        "    format = imghdr.what(os.path.join(path1, file))\n",
        "    if format != 'jpg':\n",
        "        os.remove(os.path.join(path1, file))\n",
        "\n",
        "for file in files2:\n",
        "    format = imghdr.what(os.path.join(path2, file))\n",
        "    if format != 'jpg':\n",
        "        os.remove(os.path.join(path2, file))"
      ],
      "metadata": {
        "id": "vrM08WAVLx-Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    shuffle = True,\n",
        "    image_size = (256, 256),\n",
        "    batch_size = 32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "VKF4VZFHVDRI",
        "outputId": "81a99e44-2f3a-40c7-e36c-ea2e58513c7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-400d6e7e9f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m       image_paths, labels, validation_split, subset)\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     raise ValueError(f'No images found in directory {directory}. '\n\u001b[0m\u001b[1;32m    210\u001b[0m                      f'Allowed formats: {ALLOWLIST_FORMATS}')\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory PetImages. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization"
      ],
      "metadata": {
        "id": "RcXuUgF7mzhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "id": "DRYtf7lea3U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 10))\n",
        "for image_batch, label_batch in dataset.take(1):\n",
        "  for i in range(12):\n",
        "    ax = plt.subplot(3,4,i+1)\n",
        "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[label_batch[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "fa7ZMrLgbYA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split in tensorflow"
      ],
      "metadata": {
        "id": "i1wZMIBZmNrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 70% ==> training\n",
        "# 30% ==> 15% ==> validation, 15% ==> test\n",
        "# train_ds = dataset.take(547)    # train = arr[:547]\n",
        "# test_ds = dataset.skip(547)     # test = arr[547:]\n",
        "# val_ds = test_ds.take(117)      # val = test[:117]\n",
        "# test_ds = test_ds.skip(117)     # test = test[117:]\n",
        "\n",
        "def get_dataset_partitions_tf(ds, train_split=0.7, val_split=0.15, shuffle=True, shuffle_size=10000):\n",
        "  \n",
        "  ds_size = len(ds)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "  train_size = int(train_split * ds_size)\n",
        "  val_size = int(val_split * ds_size)\n",
        "\n",
        "  train_ds = ds.take(train_size)\n",
        "\n",
        "  val_ds = ds.skip(train_size).take(val_size)\n",
        "  test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "  return train_ds, val_ds, test_ds\n"
      ],
      "metadata": {
        "id": "sjFHGPLYd5Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "gSyvYRXMesWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .cache() -->\n",
        "# reads image from disk and for next iteration when same image is needed, \n",
        "# it will keep that image in memory thus improves performance of pipeline\n",
        "# .prefetch() -->\n",
        "# if GPU is busy training, it will load next set of batch from disk to CPU and improves performance\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "cII5s7Iifo95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "PhX3f_XtmYAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])"
      ],
      "metadata": {
        "id": "BwO7bf24mH5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentaiton = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "aAEaKjBFpF4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and train model"
      ],
      "metadata": {
        "id": "eiZ1M8Vf7un9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "\n",
        "model = models.Sequential([\n",
        "      resize_and_rescale,\n",
        "      data_augmentaiton,\n",
        "      layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.build(input_shape = input_shape)"
      ],
      "metadata": {
        "id": "Um0m6Cu8p1W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "M5vDeDNSDUwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "BFL_QMD4FMWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    verbose = 1,\n",
        "    validation_data = val_ds\n",
        ")"
      ],
      "metadata": {
        "id": "tL5aTAUPGTt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cwfHFFoXJb5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}